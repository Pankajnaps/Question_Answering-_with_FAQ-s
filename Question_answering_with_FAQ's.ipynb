{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce67f654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain in details about Natural Processing la...</td>\n",
       "      <td>Natural Language Processing (NLP) is designed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There have some various common elements of nat...</td>\n",
       "      <td>There have a lot of components normally using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain details about varieties areas availabl...</td>\n",
       "      <td>Natural language processing (NLP) can have an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the case of processing natural language we ...</td>\n",
       "      <td>These are the basic NLP Interview Questions as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One another very common terminology used in th...</td>\n",
       "      <td>TF-IDF or tf-IDF is basically stood for some c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>There are several tagging using for processing...</td>\n",
       "      <td>Part of speech tagger is a very interesting an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As the analysis is one of the critical require...</td>\n",
       "      <td>Pragmatic analysis is one of the critical anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Again as NLP is used for multiple language pro...</td>\n",
       "      <td>Dependency parsing is actually known in the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One of the very basic requirement of NLP is ke...</td>\n",
       "      <td>This is the most asked NLP Interview Question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There have some classification model define in...</td>\n",
       "      <td>There have several classifications followed by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  Explain in details about Natural Processing la...   \n",
       "1  There have some various common elements of nat...   \n",
       "2  Explain details about varieties areas availabl...   \n",
       "3  In the case of processing natural language we ...   \n",
       "4  One another very common terminology used in th...   \n",
       "5  There are several tagging using for processing...   \n",
       "6  As the analysis is one of the critical require...   \n",
       "7  Again as NLP is used for multiple language pro...   \n",
       "8  One of the very basic requirement of NLP is ke...   \n",
       "9  There have some classification model define in...   \n",
       "\n",
       "                                             answers  \n",
       "0  Natural Language Processing (NLP) is designed ...  \n",
       "1  There have a lot of components normally using ...  \n",
       "2  Natural language processing (NLP) can have an ...  \n",
       "3  These are the basic NLP Interview Questions as...  \n",
       "4  TF-IDF or tf-IDF is basically stood for some c...  \n",
       "5  Part of speech tagger is a very interesting an...  \n",
       "6  Pragmatic analysis is one of the critical anal...  \n",
       "7  Dependency parsing is actually known in the in...  \n",
       "8  This is the most asked NLP Interview Question ...  \n",
       "9  There have several classifications followed by...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "\n",
    "#Load dataset and examine dataset, rename columns to questions and answers\n",
    "\n",
    "df=pd.read_csv(\"FAQ_NLP_Questions.csv\",encoding='cp1252');\n",
    "df.columns=[\"questions\",\"answers\"];\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5161db6",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "For this task we are performing the following preprocessing :\n",
    "<br>-Removing all characters that are not alpha numeric\n",
    "<br>-Removing stopwords - commonly used words such as 'a', 'to', 'in' and so on.. that do not contribute to the semantic similarity between two sentences.\n",
    "<br> We apply this to both the FAQ questions and the user query sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6331b35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Stopwords:\n",
      "\n",
      "['explain details natural processing language nlp currently key artificial language learning processes started industry', 'common elements natural language processing elements essential understanding nlp properly explain example', 'explain details varieties areas available processing natural languages smartly know impacted areas small processing started recently', 'case processing natural language normally mentioned common terminology nlp binding language terminology properly explain details nlp terminology example', 'common terminology case natural learning processing called tfidf explain details understanding tfidf properly come example', 'tagging processing natural languages tagging parts speech pos tagging industrys popular ones explain speech pos tagging properly', 'analysis critical requirements natural language processing nlp follow analysis approaches understanding nlp properly key analysis called pragmatic analysis explain pragmatic analysis details', 'nlp multiple language processing smartly interacting based proper language understanding key parsings normally nlp dependency parsing explain dependency parsing details proper explanation', 'basic requirement nlp keyword normalization normally process techniques followed nlp handling proper keyword normalization explain details keyword normalization techniques followed', 'classification model define nlp kind features followed nlp improving accuracy classification model']\n",
      "\n",
      "\n",
      "With Stopwords:\n",
      "\n",
      "['explain in details about natural processing language nlp  which is currently one of the key artificial language learning processes that have been started in the industry', 'there have some various common elements of natural language processing those elements are essential for understanding nlp properly can you please explain the same in detail with an example', 'explain details about varieties areas available in processing natural languages smartly whether we know impacted areas are very small as this processing started very recently', 'in the case of processing natural language we normally mentioned one common terminology nlp and binding every language with the same terminology properly please explain in details about this nlp terminology with an example', 'one another very common terminology used in the case of natural learning processing is called tfidf please explain in details on the understanding of tfidf properly and come with some example', 'there are several tagging using for processing natural languages in all those tagging parts of speech pos tagging is one of our industrys popular ones please explain in detail about the part of speech pos tagging and how it can be used properly', 'as the analysis is one of the critical requirements of natural language processing nlp we can follow several analysis approaches for understanding nlp properly in between all those one of the key analysis called pragmatic analysis please explain about pragmatic analysis in details', 'again as nlp is used for multiple language processing smartly and interacting with a computer system based on proper language understanding one of the key parsings normally used by nlp is dependency parsing please explain dependency parsing in details with proper explanation', 'one of the very basic requirement of nlp is keyword normalization there have normally two process or techniques followed by nlp for handling proper keyword normalization please explain in details about keyword normalization and which techniques can be followed for the same', 'there have some classification model define in nlp what kind of features can be followed by nlp for improving accuracy in the classification model']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "#from nltk.stem.lancaster import LancasterStemmer\n",
    "#st = LancasterStemmer()\n",
    "\n",
    "def clean_sentence(sentence, stopwords=False):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    \n",
    "    if stopwords:\n",
    "         sentence = remove_stopwords(sentence)\n",
    "    \n",
    "    return sentence\n",
    "                    \n",
    "def get_cleaned_sentences(df,stopwords=False):    \n",
    "    sents=df[[\"questions\"]];\n",
    "    cleaned_sentences=[]\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        #print(index,row)\n",
    "        cleaned=clean_sentence(row[\"questions\"],stopwords);\n",
    "        cleaned_sentences.append(cleaned);\n",
    "    return cleaned_sentences;\n",
    "\n",
    "cleaned_sentences=get_cleaned_sentences(df,stopwords=True)\n",
    "print(\"Without Stopwords:\\n\")\n",
    "print(cleaned_sentences);\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"With Stopwords:\\n\")\n",
    "cleaned_sentences_with_stopwords=get_cleaned_sentences(df,stopwords=False)\n",
    "print(cleaned_sentences_with_stopwords);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd32cef",
   "metadata": {},
   "source": [
    "# Bag of words model\n",
    "The first model we will use for semantic similarity is leveraging Bag of Words (BOW). With BOW, each sentence is encoded into a vector whose length is the number of words in the vocabulary. Each element of the vector indicates how many times the particular word occurs in the sentence. <br>Note that a vector representation of a sentence is often also called an \"Embedding\" since it is a way of embedding a sentence in M-dimensional space if the vector is of length M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343e4fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  about\n",
      "1  :  artificial\n",
      "2  :  been\n",
      "3  :  currently\n",
      "4  :  details\n",
      "5  :  explain\n",
      "6  :  have\n",
      "7  :  in\n",
      "8  :  industry\n",
      "9  :  is\n",
      "10  :  key\n",
      "11  :  language\n",
      "12  :  learning\n",
      "13  :  natural\n",
      "14  :  nlp\n",
      "15  :  of\n",
      "16  :  one\n",
      "17  :  processes\n",
      "18  :  processing\n",
      "19  :  started\n",
      "20  :  that\n",
      "21  :  the\n",
      "22  :  which\n",
      "23  :  an\n",
      "24  :  are\n",
      "25  :  can\n",
      "26  :  common\n",
      "27  :  detail\n",
      "28  :  elements\n",
      "29  :  essential\n",
      "30  :  example\n",
      "31  :  for\n",
      "32  :  please\n",
      "33  :  properly\n",
      "34  :  same\n",
      "35  :  some\n",
      "36  :  there\n",
      "37  :  those\n",
      "38  :  understanding\n",
      "39  :  various\n",
      "40  :  with\n",
      "41  :  you\n",
      "42  :  areas\n",
      "43  :  as\n",
      "44  :  available\n",
      "45  :  impacted\n",
      "46  :  know\n",
      "47  :  languages\n",
      "48  :  recently\n",
      "49  :  small\n",
      "50  :  smartly\n",
      "51  :  this\n",
      "52  :  varieties\n",
      "53  :  very\n",
      "54  :  we\n",
      "55  :  whether\n",
      "56  :  and\n",
      "57  :  binding\n",
      "58  :  case\n",
      "59  :  every\n",
      "60  :  mentioned\n",
      "61  :  normally\n",
      "62  :  terminology\n",
      "63  :  another\n",
      "64  :  called\n",
      "65  :  come\n",
      "66  :  on\n",
      "67  :  tfidf\n",
      "68  :  used\n",
      "69  :  all\n",
      "70  :  be\n",
      "71  :  how\n",
      "72  :  industrys\n",
      "73  :  it\n",
      "74  :  ones\n",
      "75  :  our\n",
      "76  :  part\n",
      "77  :  parts\n",
      "78  :  popular\n",
      "79  :  pos\n",
      "80  :  several\n",
      "81  :  speech\n",
      "82  :  tagging\n",
      "83  :  using\n",
      "84  :  analysis\n",
      "85  :  approaches\n",
      "86  :  between\n",
      "87  :  critical\n",
      "88  :  follow\n",
      "89  :  pragmatic\n",
      "90  :  requirements\n",
      "91  :  a\n",
      "92  :  again\n",
      "93  :  based\n",
      "94  :  by\n",
      "95  :  computer\n",
      "96  :  dependency\n",
      "97  :  explanation\n",
      "98  :  interacting\n",
      "99  :  multiple\n",
      "100  :  parsing\n",
      "101  :  parsings\n",
      "102  :  proper\n",
      "103  :  system\n",
      "104  :  basic\n",
      "105  :  followed\n",
      "106  :  handling\n",
      "107  :  keyword\n",
      "108  :  normalization\n",
      "109  :  or\n",
      "110  :  process\n",
      "111  :  requirement\n",
      "112  :  techniques\n",
      "113  :  two\n",
      "114  :  accuracy\n",
      "115  :  classification\n",
      "116  :  define\n",
      "117  :  features\n",
      "118  :  improving\n",
      "119  :  kind\n",
      "120  :  model\n",
      "121  :  what\n",
      "explain in details about natural processing language nlp  which is currently one of the key artificial language learning processes that have been started in the industry\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1)]\n",
      "there have some various common elements of natural language processing those elements are essential for understanding nlp properly can you please explain the same in detail with an example\n",
      "[(5, 1), (6, 1), (7, 1), (11, 1), (13, 1), (14, 1), (15, 1), (18, 1), (21, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 2), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1)]\n",
      "explain details about varieties areas available in processing natural languages smartly whether we know impacted areas are very small as this processing started very recently\n",
      "[(0, 1), (4, 1), (5, 1), (7, 1), (13, 1), (18, 2), (19, 1), (24, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 2), (54, 1), (55, 1)]\n",
      "in the case of processing natural language we normally mentioned one common terminology nlp and binding every language with the same terminology properly please explain in details about this nlp terminology with an example\n",
      "[(0, 1), (4, 1), (5, 1), (7, 2), (11, 2), (13, 1), (14, 2), (15, 1), (16, 1), (18, 1), (21, 2), (23, 1), (26, 1), (30, 1), (32, 1), (33, 1), (34, 1), (40, 2), (51, 1), (54, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 3)]\n",
      "one another very common terminology used in the case of natural learning processing is called tfidf please explain in details on the understanding of tfidf properly and come with some example\n",
      "[(4, 1), (5, 1), (7, 2), (9, 1), (12, 1), (13, 1), (15, 2), (16, 1), (18, 1), (21, 2), (26, 1), (30, 1), (32, 1), (33, 1), (35, 1), (38, 1), (40, 1), (53, 1), (56, 1), (58, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 2), (68, 1)]\n",
      "there are several tagging using for processing natural languages in all those tagging parts of speech pos tagging is one of our industrys popular ones please explain in detail about the part of speech pos tagging and how it can be used properly\n",
      "[(0, 1), (5, 1), (7, 2), (9, 1), (13, 1), (15, 3), (16, 1), (18, 1), (21, 1), (24, 1), (25, 1), (27, 1), (31, 1), (32, 1), (33, 1), (36, 1), (37, 1), (47, 1), (56, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 2), (80, 1), (81, 2), (82, 4), (83, 1)]\n",
      "as the analysis is one of the critical requirements of natural language processing nlp we can follow several analysis approaches for understanding nlp properly in between all those one of the key analysis called pragmatic analysis please explain about pragmatic analysis in details\n",
      "[(0, 1), (4, 1), (5, 1), (7, 2), (9, 1), (10, 1), (11, 1), (13, 1), (14, 2), (15, 3), (16, 2), (18, 1), (21, 3), (25, 1), (31, 1), (32, 1), (33, 1), (37, 1), (38, 1), (43, 1), (54, 1), (64, 1), (69, 1), (80, 1), (84, 5), (85, 1), (86, 1), (87, 1), (88, 1), (89, 2), (90, 1)]\n",
      "again as nlp is used for multiple language processing smartly and interacting with a computer system based on proper language understanding one of the key parsings normally used by nlp is dependency parsing please explain dependency parsing in details with proper explanation\n",
      "[(4, 1), (5, 1), (7, 1), (9, 2), (10, 1), (11, 2), (14, 2), (15, 1), (16, 1), (18, 1), (21, 1), (31, 1), (32, 1), (38, 1), (40, 2), (43, 1), (50, 1), (56, 1), (61, 1), (66, 1), (68, 2), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 2), (97, 1), (98, 1), (99, 1), (100, 2), (101, 1), (102, 2), (103, 1)]\n",
      "one of the very basic requirement of nlp is keyword normalization there have normally two process or techniques followed by nlp for handling proper keyword normalization please explain in details about keyword normalization and which techniques can be followed for the same\n",
      "[(0, 1), (4, 1), (5, 1), (6, 1), (7, 1), (9, 1), (14, 2), (15, 2), (16, 1), (21, 2), (22, 1), (25, 1), (31, 2), (32, 1), (34, 1), (36, 1), (53, 1), (56, 1), (61, 1), (70, 1), (94, 1), (102, 1), (104, 1), (105, 2), (106, 1), (107, 3), (108, 3), (109, 1), (110, 1), (111, 1), (112, 2), (113, 1)]\n",
      "there have some classification model define in nlp what kind of features can be followed by nlp for improving accuracy in the classification model\n",
      "[(6, 1), (7, 2), (14, 2), (15, 1), (21, 1), (25, 1), (31, 1), (35, 1), (36, 1), (70, 1), (94, 1), (105, 1), (114, 1), (115, 2), (116, 1), (117, 1), (118, 1), (119, 1), (120, 2), (121, 1)]\n",
      "\n",
      "\n",
      " what really natural language processing is \n",
      " [(9, 1), (11, 1), (13, 1), (18, 1), (121, 1)]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "sentences=cleaned_sentences_with_stopwords\n",
    "#sentences=cleaned_sentences\n",
    "\n",
    "# Split it by white space \n",
    "sentence_words = [[word for word in document.split() ]\n",
    "         for document in sentences]\n",
    "\n",
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(sentence_words)\n",
    "for key, value in dictionary.items():\n",
    "    print(key, ' : ', value)\n",
    "\n",
    "import pprint\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in sentence_words]\n",
    "for sent,embedding in zip(sentences,bow_corpus):\n",
    "    print(sent)\n",
    "    print(embedding)\n",
    "\n",
    "question_orig=\"What really natural language processing is?\"\n",
    "question=clean_sentence(question_orig,stopwords=False);\n",
    "question_embedding = dictionary.doc2bow(question.split())\n",
    "\n",
    "\n",
    "print(\"\\n\\n\",question,\"\\n\",question_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5f96d",
   "metadata": {},
   "source": [
    "# cosine similarity\n",
    "Once we find a vector representation for each sentence using BOW,we can compute the distance between two vectors by taking the cosine similarity. Note other similarity measure can be used as well, but we will stick to cosine similarity throughout for simplicity.\n",
    "<br>The closest matching answer can be retrieved by finding the cosine similarity of the query vector with each of the FAQ question vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aefb3d38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.11043152607484653 explain in details about natural processing language nlp  which is currently one of the key artificial language learning processes that have been started in the industry\n",
      "1 0.996240588195683 there have some various common elements of natural language processing those elements are essential for understanding nlp properly can you please explain the same in detail with an example\n",
      "2 0.11043152607484653 explain details about varieties areas available in processing natural languages smartly whether we know impacted areas are very small as this processing started very recently\n",
      "3 0.11043152607484653 in the case of processing natural language we normally mentioned one common terminology nlp and binding every language with the same terminology properly please explain in details about this nlp terminology with an example\n",
      "4 0.9909924304103231 one another very common terminology used in the case of natural learning processing is called tfidf please explain in details on the understanding of tfidf properly and come with some example\n",
      "5 0.11043152607484653 there are several tagging using for processing natural languages in all those tagging parts of speech pos tagging is one of our industrys popular ones please explain in detail about the part of speech pos tagging and how it can be used properly\n",
      "6 0.11043152607484653 as the analysis is one of the critical requirements of natural language processing nlp we can follow several analysis approaches for understanding nlp properly in between all those one of the key analysis called pragmatic analysis please explain about pragmatic analysis in details\n",
      "7 0.9909924304103231 again as nlp is used for multiple language processing smartly and interacting with a computer system based on proper language understanding one of the key parsings normally used by nlp is dependency parsing please explain dependency parsing in details with proper explanation\n",
      "8 0.11043152607484653 one of the very basic requirement of nlp is keyword normalization there have normally two process or techniques followed by nlp for handling proper keyword normalization please explain in details about keyword normalization and which techniques can be followed for the same\n",
      "9 0.998515707930946 there have some classification model define in nlp what kind of features can be followed by nlp for improving accuracy in the classification model\n",
      "\n",
      "\n",
      "Question:  what really natural language processing is\n",
      "\n",
      "\n",
      "Retrieved:  There have some classification model define in NLP. What kind of features can be followed by NLP for improving accuracy in the classification model?\n",
      "There have several classifications followed by NLP explaining the same below: 1)Counting frequency of defined terms. 2)Notation of vector for every sentence. 3)Part of Speech (POS) tagging. 4)Grammatical dependency or some defined dictionary or library.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity;\n",
    "def retrieveAndPrintFAQAnswer(question_embedding,sentence_embeddings,FAQdf,sentences):\n",
    "    max_sim=-1;\n",
    "    index_sim=-1;\n",
    "    for index,faq_embedding in enumerate(sentence_embeddings):\n",
    "        #sim=cosine_similarity(embedding.reshape(1, -1),question_embedding.reshape(1, -1))[0][0];\n",
    "        sim=cosine_similarity(faq_embedding,question_embedding)[0][0];\n",
    "        print(index, sim, sentences[index])\n",
    "        if sim>max_sim:\n",
    "            max_sim=sim;\n",
    "            index_sim=index;\n",
    "       \n",
    "    print(\"\\n\")\n",
    "    print(\"Question: \",question)\n",
    "    print(\"\\n\");\n",
    "    print(\"Retrieved: \",FAQdf.iloc[index_sim,0]) \n",
    "    print(FAQdf.iloc[index_sim,1])        \n",
    "    \n",
    "retrieveAndPrintFAQAnswer(question_embedding,bow_corpus,df,sentences);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd25cd",
   "metadata": {},
   "source": [
    "# Word2Vec Embeddings\n",
    "Word2Vec ebeddings are popularly trained using the skipgram model. These embeddings are trained to take a word as input and reconstruct its context. As a result, they are able to take into account semantic similarity of words based on context information. The resulting embeddings are such that words with similar meaning tend to be closer in terms of cosine similarity.\n",
    "# Skipgram model :\n",
    "The most popular word2vec model is the skipgram model. Particularly, the most commonly used pre-trained model is based on the Google News dataset that has 3 billion running words and creates upto 300 dimensional embedding for 3 Million words.\n",
    "# Glove Embeddings :\n",
    "Glove is an alternate approach to build word embeddings using matrix factorization techinques on the word-word co-occurance matrix.<br>While both the techniques are popular, glove performs better on some datasets while word2vec skipgram model performs better on some. Here, we experiment with both the word2vec and the glove models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6a8dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded glove model\n",
      "Loaded w2v model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gensim.models import Word2Vec \n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "glove_model=None;\n",
    "try:\n",
    "    glove_model = gensim.models.KeyedVectors.load(\"./glovemodel.mod\")\n",
    "    print(\"Loaded glove model\")\n",
    "except:            \n",
    "    glove_model = api.load('glove-twitter-25')\n",
    "    glove_model.save(\"./glovemodel.mod\")\n",
    "    print(\"Saved glove model\")\n",
    "    \n",
    "v2w_model=None;\n",
    "try:\n",
    "    v2w_model = gensim.models.KeyedVectors.load(\"./w2vecmodel.mod\")\n",
    "    print(\"Loaded w2v model\")\n",
    "except:            \n",
    "    v2w_model = api.load('word2vec-google-news-300')\n",
    "    v2w_model.save(\"./w2vecmodel.mod\")\n",
    "    print(\"Saved glove model\")\n",
    "\n",
    "w2vec_embedding_size=len(v2w_model['computer']);\n",
    "glove_embedding_size=len(glove_model['computer']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e109f",
   "metadata": {},
   "source": [
    "# Finding phrase embedding from word embeddings\n",
    "To find the phrase embedding, there are several specialized techniques, the most simple technique to convert word embeddings to phrase embeddings is applicable to word2vec and glove embeddings, is to sum up the individual word embeddings in the phrase to get the phrase vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c9840a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getWordVec(word,model):\n",
    "        samp=model['computer'];\n",
    "        vec=[0]*len(samp);\n",
    "        try:\n",
    "                vec=model[word];\n",
    "        except:\n",
    "                vec=[0]*len(samp);\n",
    "        return (vec)\n",
    "\n",
    "\n",
    "def getPhraseEmbedding(phrase,embeddingmodel):\n",
    "                       \n",
    "        samp=getWordVec('computer', embeddingmodel);\n",
    "        vec=numpy.array([0]*len(samp));\n",
    "        den=0;\n",
    "        for word in phrase.split():\n",
    "            #print(word)\n",
    "            den=den+1;\n",
    "            vec=vec+numpy.array(getWordVec(word,embeddingmodel));\n",
    "        #vec=vec/den;\n",
    "        #return (vec.tolist());\n",
    "        return vec.reshape(1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c939924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.809038982448252 explain details natural processing language nlp currently key artificial language learning processes started industry\n",
      "1 0.7357250616707345 common elements natural language processing elements essential understanding nlp properly explain example\n",
      "2 0.6672128531896241 explain details varieties areas available processing natural languages smartly know impacted areas small processing started recently\n",
      "3 0.6695720880902569 case processing natural language normally mentioned common terminology nlp binding language terminology properly explain details nlp terminology example\n",
      "4 0.722072672357894 common terminology case natural learning processing called tfidf explain details understanding tfidf properly come example\n",
      "5 0.5505312478214434 tagging processing natural languages tagging parts speech pos tagging industrys popular ones explain speech pos tagging properly\n",
      "6 0.5585174439833444 analysis critical requirements natural language processing nlp follow analysis approaches understanding nlp properly key analysis called pragmatic analysis explain pragmatic analysis details\n",
      "7 0.6484540229811004 nlp multiple language processing smartly interacting based proper language understanding key parsings normally nlp dependency parsing explain dependency parsing details proper explanation\n",
      "8 0.487078953277367 basic requirement nlp keyword normalization normally process techniques followed nlp handling proper keyword normalization explain details keyword normalization techniques followed\n",
      "9 0.4481884199205031 classification model define nlp kind features followed nlp improving accuracy classification model\n",
      "\n",
      "\n",
      "Question:  what really natural language processing is\n",
      "\n",
      "\n",
      "Retrieved:  Explain in details about Natural Processing language (NLP)  which is currently one of the key artificial language learning processes that have been started in the industry?\n",
      "Natural Language Processing (NLP) is designed for understanding and analyzing the natural languages automatic way and export data or possibly require information from those available data. NLP has defined an algorithm that helps mainly with machine learning. This kind of machine learning algorithm actually helps for understanding analyzing some of the natural languages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#With w2Vec\n",
    "\n",
    "sent_embeddings=[];\n",
    "for sent in cleaned_sentences:\n",
    "    sent_embeddings.append(getPhraseEmbedding(sent,v2w_model));\n",
    "\n",
    "question_embedding=getPhraseEmbedding(question,v2w_model);\n",
    "\n",
    "retrieveAndPrintFAQAnswer(question_embedding,sent_embeddings,df, cleaned_sentences);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c08df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9283977592726819 explain details natural processing language nlp currently key artificial language learning processes started industry\n",
      "1 0.9041228179020536 common elements natural language processing elements essential understanding nlp properly explain example\n",
      "2 0.8934297228771688 explain details varieties areas available processing natural languages smartly know impacted areas small processing started recently\n",
      "3 0.8921201177469507 case processing natural language normally mentioned common terminology nlp binding language terminology properly explain details nlp terminology example\n",
      "4 0.9623097698639631 common terminology case natural learning processing called tfidf explain details understanding tfidf properly come example\n",
      "5 0.8941870591043388 tagging processing natural languages tagging parts speech pos tagging industrys popular ones explain speech pos tagging properly\n",
      "6 0.8484073726956479 analysis critical requirements natural language processing nlp follow analysis approaches understanding nlp properly key analysis called pragmatic analysis explain pragmatic analysis details\n",
      "7 0.8403776789789008 nlp multiple language processing smartly interacting based proper language understanding key parsings normally nlp dependency parsing explain dependency parsing details proper explanation\n",
      "8 0.7772924332808558 basic requirement nlp keyword normalization normally process techniques followed nlp handling proper keyword normalization explain details keyword normalization techniques followed\n",
      "9 0.8658407343136372 classification model define nlp kind features followed nlp improving accuracy classification model\n",
      "\n",
      "\n",
      "Question:  what really natural language processing is\n",
      "\n",
      "\n",
      "Retrieved:  One another very common terminology used in the case of natural learning processing is called TF-IDF. Please explain in details on the understanding of TFIDF properly and come with some example?\n",
      "TF-IDF or tf-IDF is basically stood for some critical frequency of term or some inverse frequency of a specific document. TF-IDF is basically using for identifying some of the keywords from an entire document written in natural language. It mainly involves retrieving information from the critical document by using some statistical numeric data for identifying some of the keywords and mentioning how much important that word is specifically in the collection of multiple documents or in the set of collections.\n"
     ]
    }
   ],
   "source": [
    "#With Glove\n",
    "\n",
    "sent_embeddings=[];\n",
    "for sent in cleaned_sentences:\n",
    "    sent_embeddings.append(getPhraseEmbedding(sent,glove_model));\n",
    "    \n",
    "question_embedding=getPhraseEmbedding(question,glove_model);\n",
    "\n",
    "retrieveAndPrintFAQAnswer(question_embedding,sent_embeddings,df, cleaned_sentences);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0e083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499d71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
